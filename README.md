# ü§ñ Entrenamiento de Agentes con Q-Learning y SARSA

![estado](https://img.shields.io/badge/estado-completado-brightgreen) 
![tecnolog√≠as](https://img.shields.io/badge/tecnolog√≠as-Python_+_Reinforcement_Learning-blue)

## üìå Descripci√≥n  

Este proyecto compara dos algoritmos cl√°sicos de **aprendizaje por refuerzo**: **Q-Learning** y **SARSA**.  
El objetivo es entrenar agentes para adaptarse y aprender en diferentes entornos, evaluando sus comportamientos y rendimiento.  

El proyecto incluye:  
- Implementaciones propias de **Q-Learning** y **SARSA**.  
- Varios entornos de prueba (simulados).  
- Sistema de evaluaci√≥n para comparar resultados.  

---

## üöÄ Tecnolog√≠as utilizadas  

- **Lenguaje:** Python  
- **Librer√≠as:** NumPy, Matplotlib.
- **Algoritmos:**  
  - Q-Learning  
  - SARSA  

---

## üåê Environments utilizados  

El proyecto incluye entrenamiento en distintos entornos de Gym/OpenAI:  

- `FrozenLake-v1`  
- `Maze`  
- `Maze-Multigoal`  

---

## üß† Algoritmos implementados  

1. **Q-Learning**  
   - Algoritmo off-policy de aprendizaje por refuerzo.  
   - Actualiza la funci√≥n de valor Q considerando la mejor acci√≥n futura estimada.  

2. **SARSA (State-Action-Reward-State-Action)**  
   - Algoritmo on-policy.  
   - Actualiza Q considerando la acci√≥n real elegida en el siguiente estado, adapt√°ndose a la pol√≠tica exploratoria.  

---

## üñºÔ∏è Ejemplo visual del entrenamiento  

- Ejemplo de entorno y agente en acci√≥n:  
  ![Entorno](./Ejemplo.png)  

---

## üë§ Autor  

- [Enrique Morcillo Mart√≠nez](https://github.com/kitex03)  

---

## ‚ú® Aprendizajes  

- Compresi√≥n de los algoritmos de **Q-Learning** y **SARSA**.  
- Comprensi√≥n profunda de la diferencia entre **on-policy** y **off-policy**.  
- An√°lisis comparativo del rendimiento de los agentes seg√∫n el algoritmo y entorno.  
- Visualizaci√≥n de aprendizaje mediante gr√°ficas y simulaciones.  

